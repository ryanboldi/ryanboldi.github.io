---
@inproceedings{boldi2022environmental,
abbr={ALIFE}, 
title="The Environmental Discontinuity Hypothesis for Down-Sampled Lexicase Selection",
year="2022",
author="Boldi, Ryan and Helmuth, Thomas and Spector, Lee",
archivePrefix = "arXiv",
eprint = {2205.15931},
booktitle="2022 Conference on Artificial Life - Why it Didn't Work-Shop",
pdf="https://arxiv.org/pdf/2205.15931v1.pdf",   
abstract="Down-sampling training data has long been shown to improve the generalization performance of a wide range of machine learning systems. Recently, down-sampling has proved effective in genetic programming (GP) runs that utilize the lexicase parent selection technique. Although this down-sampling procedure has been shown to significantly improve performance across a variety of problems, it does not seem to do so due to encouraging adaptability through environmental change. We hypothesize that the random sampling that is performed every generation causes discontinuities that result in the population being unable to adapt to the shifting environment. We investigate modifications to down-sampled lexicase selection in hopes of promoting incremental environmental change to scaffold evolution by reducing the amount of jarring discontinuities between the environments of successive generations. In our empirical studies, we find that forcing incremental environmental change is not significantly better for evolving solutions to program synthesis problems than simple random down-sampling. In response to this, we attempt to exacerbate the hypothesized prevalence of discontinuities by using only disjoint down-samples to see if it hinders performance. We find that this also does not significantly differ from the performance of regular random down-sampling. These negative results raise new questions about the ways in which the composition of sub-samples, which may include synonymous cases, may be expected to influence the performance of machine learning systems that use down-sampling."
}

@inproceedings{ding2022scale,
abbr={GECCO},
title="Lexicase Selection at Scale",
year="2022",
author="Ding, Li and Boldi, Ryan and Helmuth, Thomas and Spector, Lee",
booktitle="Genetic and Evolutionary Computation Conference Companion (GECCO '22 Companion), July 9--13, 2022, Boston, MA, USA",
html="https://dl.acm.org/doi/10.1145/3520304.3534026",
abstract="Lexicase selection is a semantic-aware parent selection method, which assesses individual test cases in a randomly-shuffled data stream. It has demonstrated success in multiple research areas including genetic programming, genetic algorithms, and more recently symbolic regression and deep learning. One potential drawback of lexicase selection and its variants is that the selection procedure requires evaluating training cases in a single data stream, making it difficult to handle tasks where the evaluation is computationally heavy or the dataset is large-scale, e.g., deep learning. In this work, we investigate how the weighted shuffle methods can be employed to improve the efficiency of lexicase selection. We propose a novel method, fast lexicase selection, which incorporates lexicase selection and weighted shuffle with partial evaluation. Experiments on both classic genetic programming and deep learning tasks indicate that the proposed method can significantly reduce the number of evaluation steps needed for lexicase selection to select an individual, improving its efficiency while maintaining the performance.",
preview="/assets/img/bibAssets/scale.png"
}

@inproceedings{ding2022faster,
abbr={GECCO}, 
title="Going Faster and Hence Further with Lexicase Selection",
year="2022",
author="Ding, Li and Boldi, Ryan and Helmuth, Thomas and Spector, Lee",
booktitle="Genetic and Evolutionary Computation Conference Companion (GECCO '22 Companion), July 9--13, 2022, Boston, MA, USA",
html="https://dl.acm.org/doi/10.1145/3520304.3529059"
}
---
